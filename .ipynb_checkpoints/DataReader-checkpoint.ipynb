{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb as mdb\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "class DataReader(object):\n",
    "    '''A unified data reader interface to interact with the In-Part database.'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Connect to db and create a cursor for subsequent queries. \"\"\"\n",
    "        self.con = mdb.connect(host='localhost', user='root', passwd=\"123\", db=\"capstone\", local_infile=1) \n",
    "        self.cur = self.con.cursor() \n",
    "        \n",
    "        # Other auxiliary instance variables\n",
    "        self.user_num = None\n",
    "        self.user_ids = None\n",
    "        self.user_keywords = None\n",
    "        \n",
    "        self.tech_num = None\n",
    "        self.tech_ids = None\n",
    "        self.tech_keywords = None\n",
    "        \n",
    "        self.all_keywords = None\n",
    "        self.keyword_mapping_dict = None\n",
    "        \n",
    "        self.tech_mapping_dict = None\n",
    "\n",
    "    def get_user_num(self):\n",
    "        \"\"\"Return the number of unique users.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        long\n",
    "        \"\"\"\n",
    "        if self.user_num is not None:\n",
    "            return self.user_num\n",
    "        query = \"SELECT DISTINCT id FROM users\"\n",
    "        self.cur.execute(query)\n",
    "        self.user_num =  self.cur.rowcount\n",
    "        return long(self.user_num)\n",
    "\n",
    "    def get_user_ids(self):\n",
    "        \"\"\"Return a list of all user ids in the database. \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of long like [1L, 2L, 3L].\n",
    "        \"\"\"\n",
    "        if self.user_ids is not None:\n",
    "            return self.user_ids\n",
    "        query = \"SELECT DISTINCT id FROM users\"\n",
    "        self.cur.execute(query)\n",
    "        rows = self.cur.fetchall()\n",
    "        self.user_ids = [row[0] for row in rows]\n",
    "        return self.user_ids\n",
    "\n",
    "\n",
    "    def get_tech_num(self):\n",
    "        \"\"\"Return the number of unique technologies in the database.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        long        \n",
    "        \"\"\"\n",
    "        if self.tech_num is not None:\n",
    "            return self.tech_num\n",
    "        query = \"SELECT DISTINCT id FROM technologies\"\n",
    "        self.cur.execute(query)\n",
    "        self.technology_num = self.cur.rowcount\n",
    "        return self.technology_num\n",
    "\n",
    "    def get_tech_ids(self):\n",
    "        \"\"\"Return a list of all technologies id in the database.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of long.\n",
    "        \"\"\"\n",
    "        if self.tech_ids is not None:\n",
    "            return self.tech_ids\n",
    "        query = \"SELECT DISTINCT id FROM technologies\"\n",
    "        self.cur.execute(query)\n",
    "        rows = self.cur.fetchall()\n",
    "        self.tech_ids = [row[0] for row in rows]\n",
    "        return self.tech_ids\n",
    "\n",
    "    def get_tech_mapping_dict(self):\n",
    "        '''Return a mapping dict which maps technology id to its index in the lis of all tech ids.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "        '''\n",
    "        if self.tech_mapping_dict is not None:\n",
    "            return self.tech_mapping_dict\n",
    "        all_tech_ids = self.get_tech_ids()\n",
    "        self.tech_mapping_dict = {value: index for index, value in enumerate(all_tech_ids)}\n",
    "        return self.tech_mapping_dict\n",
    "    \n",
    "    \n",
    "    def get_all_keywords(self):\n",
    "        \"\"\"Return a list of all keywords.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list \n",
    "            A list of long.\n",
    "        \"\"\"\n",
    "        if self.all_keywords is not None:\n",
    "            return self.all_keywords\n",
    "        query = \"SELECT DISTINCT id FROM keywords\"\n",
    "        self.cur.execute(query)\n",
    "        rows = self.cur.fetchall()\n",
    "        self.all_keywords = [row[0] for row in rows]\n",
    "        return self.all_keywords\n",
    "        \n",
    "    def get_tech_keywords(self):\n",
    "        \"\"\"Return a dictionary whose key is technology id and whose value is a list of associated keywords.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict \n",
    "        \"\"\"\n",
    "        if self.tech_keywords is not None:\n",
    "            return self.tech_keywords\n",
    "        query = \"SELECT * FROM technology_keywords\"\n",
    "        self.cur.execute(query)\n",
    "        self.tech_keywords = {}\n",
    "        rows = self.cur.fetchall()\n",
    "        for row in rows:\n",
    "            if row[1] not in self.tech_keywords:\n",
    "                self.tech_keywords[row[1]] = []\n",
    "                self.tech_keywords[row[1]].append(row[0])\n",
    "            else:\n",
    "                self.tech_keywords[row[1]].append(row[0])\n",
    "        return self.tech_keywords\n",
    "    \n",
    "    def get_user_keywords(self):\n",
    "        \"\"\"Return a dictionary whose key is user id and whose value is a list of associated keywords.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict \n",
    "        \"\"\"\n",
    "        if self.user_keywords is not None:\n",
    "            return self.user_keywords\n",
    "        query = \"SELECT * FROM user_keywords\"\n",
    "        self.cur.execute(query)\n",
    "        self.user_keywords = {}\n",
    "        rows = self.cur.fetchall()\n",
    "        for row in rows:\n",
    "            if row[1] not in self.user_keywords:\n",
    "                self.user_keywords[row[1]] = []\n",
    "                self.user_keywords[row[1]].append(row[0])\n",
    "            else:\n",
    "                self.user_keywords[row[1]].append(row[0])\n",
    "        return self.user_keywords\n",
    "        \n",
    "        \n",
    "    def get_keyword_mapping_dict(self):\n",
    "        '''Return a mapping dict which maps keyword id to its index in the technology/user keyword vector.\n",
    "        \n",
    "        Note\n",
    "        ----\n",
    "        A technology id has many associated keywords. \n",
    "        A technology keyword vector of a technology id is a vector where the value of at that location of a keyword is 1 \n",
    "        if this technology id has that keyword.\n",
    "        \n",
    "        A user keyword vector has the same principle.\n",
    "        '''\n",
    "        if self.keyword_mapping_dict is not None:\n",
    "            return self.keyword_mapping_dict\n",
    "        all_keywords = self.get_all_keywords()\n",
    "        self.keyword_mapping_dict = {value: index for index, value in enumerate(all_keywords)}\n",
    "        return self.keyword_mapping_dict\n",
    "    \n",
    "    \n",
    "    def get_tech_keyword_vector(self, tech_id):\n",
    "        '''Return the technology keyword vector given a technology id.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        tech_id: long\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of int.\n",
    "        '''\n",
    "        tech_keyword_vector = np.zeros(len(self.get_all_keywords()), dtype=np.int8)\n",
    "        tech_keywords = self.get_tech_keywords().get(tech_id, None)\n",
    "        if tech_keywords is None:       # No keywords associated with this technology\n",
    "            return tech_keyword_vector\n",
    "        keyword_mapping_dict = self.get_keyword_mapping_dict()\n",
    "        indices = [keyword_mapping_dict[keyword] for keyword in tech_keywords]\n",
    "        tech_keyword_vector[indices] = 1\n",
    "        return tech_keyword_vector\n",
    "    \n",
    "    def get_user_keyword_vector(self, user_id):\n",
    "        '''Return the user keyword vector given a user id.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        user_id: str\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of int.\n",
    "        '''\n",
    "        user_keyword_vector = np.zeros(len(self.get_all_keywords()), dtype=np.int8)\n",
    "        user_keywords = self.get_user_keywords().get(user_id, None)\n",
    "        if user_keywords is None:       # No keywords associated with this user\n",
    "            return user_keyword_vector\n",
    "        keyword_mapping_dict = self.get_keyword_mapping_dict()\n",
    "        indices = [keyword_mapping_dict[keyword] for keyword in user_keywords]\n",
    "        user_keyword_vector[indices] = 1\n",
    "        return user_keyword_vector    \n",
    "    \n",
    "    def get_score_data(self):\n",
    "        \"\"\"Returns the score table.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "            A table which contains columns user_id, technology_id, total_score.\n",
    "        \"\"\"\n",
    "        self.scoreData = pd.read_sql(\"SELECT user_id, technology_id, total_score FROM score\", con = self.con)        \n",
    "        return self.scoreData\n",
    "    \n",
    "    def get_interacted_tech_ids(self, user_id):\n",
    "        \"\"\"Return a list of technology ids with which this user has interacted.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        user_id: str\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "        \"\"\"         \n",
    "        query = \"SELECT technology_id FROM score WHERE user_id = '%s'\" % user_id\n",
    "        self.cur.execute(query)              \n",
    "        rows = self.cur.fetchall()\n",
    "        return [row[0] for row in rows]\n",
    "     \n",
    "    def get_contacted_tech_ids (self, user_id):\n",
    "        \"\"\"Return a list of contacted technology ids given a user id.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of long.\n",
    "        \"\"\"\n",
    "        query =\"SELECT technology_id FROM contacts WHERE user_id = '%s'\" % user_id\n",
    "        self.cur.execute(query) \n",
    "        rows = self.cur.fetchall() \n",
    "        return [row[0] for row in rows]\n",
    "    \n",
    "    \n",
    "    def get_clicked_tech_ids (self, user_id):\n",
    "        \"\"\"Return a list of clicked technology ids in all emails containing recommended tech ids given a user id.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of long.\n",
    "        \"\"\"\n",
    "        query =\"SELECT clicked_technology_id FROM email_clicks WHERE user_id = '%s'\" % user_id\n",
    "        self.cur.execute(query) \n",
    "        rows = self.cur.fetchall() \n",
    "        return [row[0] for row in rows]\n",
    "    \n",
    "    def get_university_tech_ids(self, university_id):\n",
    "        \"\"\"Return a list of technology ids associated with this given university id.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of long.\n",
    "        \"\"\"\n",
    "        query = \"SELECT id FROM technologies WHERE university_profile_id = '%s'\" % university_id   \n",
    "        self.cur.execute(query)\n",
    "        rows = self.cur.fetchall()\n",
    "        return [row[0] for row in rows]   \n",
    "    \n",
    "    def get_orphan_tech_ids(self):\n",
    "        \"\"\"Find orphan tech ids in user_activtivies table.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            tech_ids which appear in the user_activities table, but not in the technologies table\n",
    "        \"\"\"   \n",
    "        activities = self.get_activities_table()\n",
    "        viewed_tech_ids = []\n",
    "        for index, row in activities.iterrows():\n",
    "            start = row[1].find(\"Article_id\") # Finding start from \"Article_id\"\n",
    "            end = row[1].find(\"content\")\n",
    "            tech_id = int(re.search(r'\\d+', row[1][start:end]).group(0))\n",
    "            viewed_tech_ids.append(tech_id)     \n",
    "        tech_ids = self.get_tech_ids() \n",
    "        orphan_tech_ids = list(set(tech_ids) - set(viewed_tech_ids))\n",
    "        return orphan_tech_ids\n",
    "\n",
    "    def get_contacts_table(self):\n",
    "        \"\"\"Return the contact table.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame \n",
    "            A table which contains columns user_id, technology_id, number of contacts.\n",
    "        \"\"\"\n",
    "        self.contacts = pd.read_sql( \"SELECT user_id, technology_id , count(*) as c_count FROM contacts group by user_id, technology_id\", con = self.con)    \n",
    "        return self.contacts\n",
    "    \n",
    "    def get_clicks_table(self):\n",
    "        \"\"\"Return the click table.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame   \n",
    "            A table which contains columns user_id, technology_id, number of clicks.\n",
    "        \"\"\"\n",
    "        self.clicks =  pd.read_sql( \"SELECT user_id, clicked_technology_id as technology_id, count(*) as e_count FROM email_clicks group by user_id, technology_id\", con = self.con)\n",
    "        return self.clicks\n",
    "\n",
    "    def get_activities_table(self):\n",
    "        \"\"\"Return the activities table.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame   \n",
    "            A table which contains columns user_id, details.\n",
    "        \"\"\"\n",
    "        self.activities = pd.read_sql( \"SELECT user_id, details FROM user_activities\", con = self.con) \n",
    "        return self.activities   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = DataReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "977L"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_user_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['525fea18-db1c-451d-9902-469ad4718e13',\n",
       " '525ff28d-2d28-4cf2-a4d8-468bd4718e13',\n",
       " '5260234c-9878-4d49-9d26-46b2d4718e13',\n",
       " '5260f967-7d74-4f6e-9deb-4b7fd4718e13',\n",
       " '526131a8-dbc8-401b-989a-44afd4718e13']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_user_ids()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dr.get_user_keywords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dr.get_user_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dr.get_user_keywords().get('526132a9-4280-4cc4-a2d8-42acd4718e13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_user_keyword_vector('526132a9-4280-4cc4-a2d8-42acd4718e13').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849L, [2L, 3L, 4L, 5L, 6L])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_tech_num(), dr.get_tech_ids()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 848)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dr.get_tech_mapping_dict()), max([item[1] for item in dr.get_tech_mapping_dict().items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dr.get_tech_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_tech_keyword_vector(2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1L, 2L, 3L, 4L, 5L]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_all_keywords()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7429"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( dr.get_all_keywords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35L]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_clicked_tech_ids('57d97d4a-23b8-4148-a0a5-004a0a2ae3a6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60L, 40L, 23L, 64L, 41L, 47L, 51L]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_contacted_tech_ids('532a4687-92a4-4b5b-9d92-4f05d4718e13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dr.get_orphan_tech_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dr.get_orphan_tech_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dr.get_tech_ids()) & set(dr.get_orphan_tech_ids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dr.get_tech_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_score_data()['user_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(738,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_score_data()['technology_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cosine_similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import DataReader as dr\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from scipy import sparse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EnsembleRecommender(object):\n",
    "    '''An ensemble recommender integrated from two content-based models and one item-based collaborative flitering.'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dr = DataReader()\n",
    "        \n",
    "        self.score = self.dr.get_score_data()\n",
    "        self.cb_matrix = None\n",
    "        self.interacted_cb_matrix = None\n",
    "        self.cl_matrix = None\n",
    "        self.ensemble_matrix = None\n",
    "        self.tech_keyword_matrix = self.get_tech_keyword_matrix()\n",
    "        \n",
    "    def build_content_based(self):\n",
    "        '''Build a content-based model which calculates similarity between user keyword vector and tech keyword vector.'''\n",
    "        if self.cb_matrix is not None:\n",
    "            return self.cb_matrix\n",
    "        \n",
    "        print 'Start training content_based model...'\n",
    "        start = datetime.now()\n",
    "        \n",
    "        all_user_ids = self.dr.get_user_ids()\n",
    "        user_keyword_matrix = []     # Dimension: num_users * num_keywords\n",
    "        for uid in all_user_ids:\n",
    "            user_keyword_matrix.append(self.dr.get_user_keyword_vector(uid))\n",
    "        \n",
    "        # Convert matrix to sparse matrix to speed up similarity calculation\n",
    "        user_keyword_matrix = sparse.csr_matrix(user_keyword_matrix)\n",
    "        self.tech_keyword_matrix = sparse.csr_matrix(self.tech_keyword_matrix)\n",
    "        self.cb_matrix = cosine_similarity(user_keyword_matrix, self.tech_keyword_matrix)  # Dim: num_users * num_techs\n",
    "        print 'Done'\n",
    "        print 'Time elapsed:', datetime.now() - start, '\\n'\n",
    "        \n",
    "    def build_interacted_content_based(self):\n",
    "        '''Build a intereacted cb model which calculates similarity between user preference vector and tech keyword vector.\n",
    "        \n",
    "        The user preference vector is a weighted average of tech keyword vectors with which users have interacted.\n",
    "        '''\n",
    "        if self.interacted_cb_matrix is not None:\n",
    "            return self.interacted_cb_matrix\n",
    "        \n",
    "        self.tech_keyword_matrix = self.tech_keyword_matrix.toarray()\n",
    "        \n",
    "        print 'Start training interacted content_based model...'\n",
    "        start = datetime.now()\n",
    "        all_user_ids = self.dr.get_user_ids()\n",
    "        tech_mapping_dict = self.dr.get_tech_mapping_dict()\n",
    "        user_keyword_matrix = []\n",
    "        for uid in all_user_ids:\n",
    "            interacted_tech_ids = self.dr.get_interacted_tech_ids(uid)\n",
    "            num = np.zeros(len(self.dr.get_all_keywords()), dtype=np.float32)\n",
    "            deno = 0\n",
    "            for tech_id in interacted_tech_ids:\n",
    "                d= self.score[(self.score['user_id'] == uid) & (self.score['technology_id'] == tech_id)]['total_score']\n",
    "    \n",
    "                weight = d.values[0]\n",
    "                num += weight * self.tech_keyword_matrix[tech_mapping_dict[tech_id], :]\n",
    "                deno += weight\n",
    "            if deno == 0:    # This user hasn't interacted with any technology\n",
    "                user_keyword_matrix.append(self.dr.get_user_keyword_vector(uid))\n",
    "            else:\n",
    "                user_keyword_matrix.append(num / deno)\n",
    "\n",
    "        # Convert matrix to sparse matrix to speed up similarity calculation\n",
    "        user_keyword_matrix = sparse.csr_matrix(user_keyword_matrix)\n",
    "        self.tech_keyword_matrix = sparse.csr_matrix(self.tech_keyword_matrix)\n",
    "        self.interacted_cb_matrix = cosine_similarity(user_keyword_matrix, self.tech_keyword_matrix)  # Dim: num_users * num_techs\n",
    "        print 'Done'\n",
    "        print 'Time elapsed:', datetime.now() - start, '\\n'\n",
    "            \n",
    "    def build_collaborative_filtering(self):\n",
    "        '''Built a collaborative filtering model using score table.'''\n",
    "        if self.cl_matrix is not None:\n",
    "            return self.cl_matrix\n",
    "        \n",
    "        scoreData = self.score\n",
    "        score_df = scoreData.pivot(index = 'user_id', columns = 'technology_id', values = 'total_score') # Reshape score table \n",
    "        score_df = score_df.fillna(0) # fill NaN data with 0\n",
    "\n",
    "        # Calculate Technology based similarity\n",
    "        score_df_t = score_df.T\n",
    "        score_spare_t = sparse.csr_matrix(score_df_t) \n",
    "\n",
    "        similarities_tech = cosine_similarity(score_spare_t)\n",
    "        similarities_tech_df = pd.DataFrame(similarities_tech, columns = score_df_t.index, index = score_df_t.index)\n",
    "\n",
    "        # Create a list of user_ids and tech_ids which are available in score table\n",
    "        user_ids = scoreData['user_id'].unique()\n",
    "        tech_ids = scoreData['technology_id'].unique()\n",
    "\n",
    "        # Calculate mean of all ratings, mean rating given by each user and mean rating given to each technology\n",
    "        all_mean = np.mean(scoreData['total_score'])\n",
    "        avg_user = {}\n",
    "        for user in user_ids:\n",
    "            avg_user[user] = np.mean(scoreData[scoreData['user_id'] == user]['total_score']) - all_mean\n",
    "\n",
    "        avg_tech = {}\n",
    "        for tech in tech_ids:\n",
    "            avg_tech[tech] = np.mean(scoreData[scoreData['technology_id'] == tech]['total_score'])-all_mean\n",
    "        \n",
    "        \n",
    "        print 'Start training collaborative filtering model...'\n",
    "        start = datetime.now()\n",
    "        count = 0\n",
    "        base_line = {}\n",
    "        prediction = {} # A dictionary storing predictions whose key is a tuple (user_id, tech_id)\n",
    "        \n",
    "        print 'Total num of calculation:', len(user_ids) * len(tech_ids)\n",
    "        for i in itertools.product(user_ids,tech_ids):\n",
    "            prediction[i] = score_df.ix[i[0],i[1]]\n",
    "            base_line[i] = avg_user[i[0]] + avg_tech[i[1]] + all_mean\n",
    "            if prediction[i] == 0:\n",
    "                numerator = sum((score_df.ix[i[0]] - base_line[i])*similarities_tech_df.ix[i[1]])\n",
    "                denominator = sum(similarities_tech_df.ix[i[1]])-1\n",
    "                if denominator == 0:\n",
    "                    prediction[i] = 0\n",
    "                else:\n",
    "                    prediction[i] = base_line[i] + numerator/float(denominator)\n",
    "                    count += 1\n",
    "                    if count % 100000 == 0:\n",
    "                        print 'Num of calcuation finished:', count,\n",
    "                        print '\\tTime elapsed:', datetime.now() - start\n",
    "\n",
    "        idx = pd.MultiIndex.from_tuples(prediction.keys())\n",
    "        item_based_cf = pd.DataFrame(list(prediction.values()),index = idx,columns = ['Technology_id']).unstack(fill_value = 0)['Technology_id']\n",
    "        item_based_cf = item_based_cf.loc[self.dr.get_user_ids(), self.dr.get_tech_ids()].fillna(0)\n",
    "        self.cl_matrix = item_based_cf.values\n",
    "        print 'Done'\n",
    "        print 'Time elapsed:', datetime.now() - start, '\\n'\n",
    "        \n",
    "    \n",
    "    def build_ensemble_model(self, weights):\n",
    "        '''Build an ensemble model.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        weights: list\n",
    "            Ensemble weights of item_based cf, content_based, interacted_content_based.\n",
    "        '''\n",
    "        if self.ensemble_matrix is not None:\n",
    "            return self.ensemble_matrix\n",
    "        index = self.dr.get_user_ids()\n",
    "        cols = self.dr.get_tech_ids()\n",
    "        norm_item_based_cf = self.normalize_df(pd.DataFrame(self.cl_matrix, index=index, columns=cols))\n",
    "        norm_cb = self.normalize_df(pd.DataFrame(self.cb_matrix, index=index, columns=cols))\n",
    "        norm_interacted_cb = self.normalize_df(pd.DataFrame(self.interacted_cb_matrix, index=index, columns=cols))\n",
    "        \n",
    "        weighted_ensemble = norm_item_based_cf * weights[0] + norm_cb * weights[1] + norm_interacted_cb * weights[2]\n",
    "        self.ensemble_matrix = weighted_ensemble\n",
    "    \n",
    "    def ensemble_recommend(self, uid, k):\n",
    "        '''Return top k recommendations for a user id.'''\n",
    "        user_preds = zip(self.ensemble_matrix.loc[uid], self.dr.get_tech_ids())\n",
    "        user_preds = sorted(user_preds, key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        contacted_ids = self.dr.get_contacted_tech_ids(uid)\n",
    "        top_k = [item_id for score, item_id in user_preds if item_id not in contacted_ids][:k]\n",
    "        \n",
    "        clicked_tech_ids = self.dr.get_clicked_tech_ids(uid)\n",
    "        email_clicked = [tech_id for tech_id in top_k if long(tech_id) in clicked_tech_ids]\n",
    "        return top_k, email_clicked\n",
    "\n",
    "    def save_recommendations_to_database(self, k):\n",
    "        '''Create a table and Write top k recommendations for each user to the database.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        k: int\n",
    "            The number of recommendations for each user.\n",
    "        '''\n",
    "        uids = self.dr.get_user_ids()\n",
    "        result = [ensemble_recommend(uid, k) for uid in uids]\n",
    "        recommendations = [item[0] for item in result]\n",
    "        email_clicked = [item[1] for item in result]\n",
    "        output = pd.concat([pd.DataFrame({'user_id': uids}), pd.DataFrame(recommendations), pd.DataFrame({'email_clicked': email_clicked})], axis=1)\n",
    "        output.to_csv('ensemble_recommendations_for_users.txt', sep='\\t', index=False, header=False)\n",
    "        \n",
    "        top_k_str = \"\"\n",
    "        for i in range(1, k + 1):\n",
    "            top_k_str += \"top_\" + str(i) + \" int, \"\n",
    "        self.dr.cur.execute(\"DROP TABLE IF EXISTS RecommendationResultForUsers;\")\n",
    "        self.dr.cur.execute('''CREATE TABLE RecommendationResultForUsers (\n",
    "                                   user_id VARCHAR(60),\n",
    "                                   %s \n",
    "                                   email_clicked VARCHAR(220));''' % top_k_str)\n",
    "        self.dr.cur.execute('''LOAD DATA LOCAL INFILE 'ensemble_recommendations_for_users.txt' \n",
    "                                   INTO TABLE RecommendationResultForUsers \n",
    "                                   FIELDS TERMINATED BY '\\t' \n",
    "                                   LINES TERMINATED BY '\\n';''')\n",
    "        self.dr.con.commit()\n",
    "\n",
    "    \n",
    "    def get_tech_keyword_matrix(self):\n",
    "        all_tech_ids = self.dr.get_tech_ids()\n",
    "        tech_keyword_matrix = []     # Dimension: num_techs * num_keywords\n",
    "        for tech_id in all_tech_ids:\n",
    "            tech_keyword_matrix.append(self.dr.get_tech_keyword_vector(tech_id))\n",
    "        return tech_keyword_matrix\n",
    "    \n",
    "    def normalize_df(self, score_matrix):\n",
    "        '''Normalize the range of each user's score to [0,1].\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        score_matrix: DataFrame\n",
    "            Row is user, Column is technology, Value is the score. Recommendations are made by ranking scores for a user.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "        '''\n",
    "        norm_df = score_matrix.copy()\n",
    "        for idx, row in norm_df.iterrows():\n",
    "            min_val = min(row)\n",
    "            max_val = max(row)\n",
    "            interval = max_val - min_val\n",
    "            if interval == 0:\n",
    "                continue\n",
    "            norm_df.ix[idx] = [(r - min_val) / interval for r in row]\n",
    "        return norm_df\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    weights = [0.65, 0.67, 0.52]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'top_1 int, top_2 int, top_3 int, top_4 int, top_5 int, '"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        top_k_str = \"\"\n",
    "        for i in range(1, 5 + 1):\n",
    "            top_k_str += \"top_\" + str(i) + \" int, \"\n",
    "        top_k_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DataReaderplus import *\n",
    "cols = weighted_ensemble.columns\n",
    "dr = DataReader()\n",
    "\n",
    "def ensemble_recommend(uid, k):\n",
    "    ''' Returns top k recommendations for a user id '''\n",
    "    user_preds = zip(weighted_ensemble.loc[uid], cols)\n",
    "    user_preds = sorted(user_preds, key=lambda x: x[0], reverse=True)\n",
    "    contact_ids = dr.get_contacted_tech_ids(uid)\n",
    "    top_k = [item_id for score, item_id in user_preds if item_id not in contact_ids][:k]\n",
    "    return top_k\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    time = datetime.now()\n",
    "    uids = user_pool\n",
    "    recommendations = [ensemble_recommend(uid, 5) for uid in uids]\n",
    "    df = pd.DataFrame(recommendations)\n",
    "    email_clicked = []\n",
    "    for i, uid in enumerate(uids):\n",
    "        email_clicked.append([int(tech_id)  for tech_id in recommendations[i] if long(tech_id) in dr.get_clicked_tech_ids(uid)])\n",
    "    output = pd.concat([pd.DataFrame({'user_id': uids}), df, pd.DataFrame({'email_clicked': email_clicked})], axis=1)\n",
    "    output.to_csv('ensemble_recommendations.csv', index=False)\n",
    "    print 'Time elapsed: ', datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = EnsembleRecommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training content_based model...\n",
      "Done\n",
      "Time elapsed: 0:00:00.191848 \n",
      "\n",
      "Start training interacted content_based model...\n",
      "Done\n",
      "Time elapsed: 0:00:15.971555 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.build_content_based()\n",
    "e.build_interacted_content_based()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training collaborative filtering model...\n",
      "Total num of calculation: 593352\n",
      "Num of calcuation finished: 100000 \tTime elapsed: 0:01:21.140684\n",
      "Num of calcuation finished: 200000 \tTime elapsed: 0:02:37.001720\n",
      "Num of calcuation finished: 300000 \tTime elapsed: 0:03:56.585435\n",
      "Num of calcuation finished: 400000 \tTime elapsed: 0:05:12.438050\n",
      "Num of calcuation finished: 500000 \tTime elapsed: 0:06:33.723254\n",
      "Done\n",
      "Time elapsed: 0:07:45.710770 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.build_collaborative_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e.build_ensemble_model([0.65, 0.67, 0.52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(977, 849)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.ensemble_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('525fea18-db1c-451d-9902-469ad4718e13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'525fea18-db1c-451d-9902-469ad4718e13',\n",
       "       u'525ff28d-2d28-4cf2-a4d8-468bd4718e13',\n",
       "       u'5260234c-9878-4d49-9d26-46b2d4718e13',\n",
       "       u'5260f967-7d74-4f6e-9deb-4b7fd4718e13',\n",
       "       u'526131a8-dbc8-401b-989a-44afd4718e13',\n",
       "       u'526132a9-4280-4cc4-a2d8-42acd4718e13',\n",
       "       u'526640ab-ebd8-4593-9749-4002d4718e13',\n",
       "       u'52698ff9-0470-47c7-b027-d9c9d4718e13',\n",
       "       u'5283a1d7-dae0-4d34-b38f-493cd4718e13',\n",
       "       u'5283aeaa-d9e4-46ec-a318-3a1ed4718e13',\n",
       "       ...\n",
       "       u'5876357e-50a8-4584-bdbd-00860a2ac68a',\n",
       "       u'5877557e-bbac-4e3f-944a-00810a2a6136',\n",
       "       u'58775f13-5944-46d8-9ec7-00bd0a2a6136',\n",
       "       u'587788f1-a39c-473f-8294-008a0a2a6136',\n",
       "       u'5877e33e-21f8-472f-be30-00b70a2ac68a',\n",
       "       u'58788ee8-bd40-4c20-992f-008a0a2a6136',\n",
       "       u'5878982f-92f8-4803-8c4a-008a0a2a6136',\n",
       "       u'5878c1c5-fe60-4018-9a89-00810a2a6136',\n",
       "       u'5878f2d1-a1a8-4155-b583-00320a2a9d99',\n",
       "       u'5879fa50-eecc-4812-8892-002f0a2a2cca'],\n",
       "      dtype='object', length=977)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.ensemble_matrix.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([504L, 516L, 253L, 503L, 783L, 510L, 168L, 807L, 365L, 499L],\n",
       " [504L, 516L, 253L, 503L, 510L, 168L])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.ensemble_recommend('57ea95e3-5d44-4330-81df-00500a2abcf8', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(977, 849)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.cl_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-176-09420479894e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-176-09420479894e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    dr.get_score_data()[()'user_id'=='528f575a-c6a8-4fdb-9bd7-4662d4718e13') & 'technology_id' == 17L]['total_score']\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dr.get_score_data()[()'user_id'=='528f575a-c6a8-4fdb-9bd7-4662d4718e13') & 'technology_id' == 17L]['total_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = dr.get_score_data()\n",
    "s[(s['user_id']=='528f575a-c6a8-4fdb-9bd7-4662d4718e13') & (s['technology_id'] == 17L)]['total_score'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = EnsembleRecommender()\n",
    "e.build_content_based()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_tech_keyword_vector(3l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse.csr_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosine_similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(e.tech_keyword_matrix.toarray(), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.tech_keyword_matrix.toarray()[1, :].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(10, dtype=np.int8) + np.ones(10, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(10).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
