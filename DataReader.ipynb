{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb as mdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "class DataReader(object):\n",
    "    '''A unified data reader interface to interact with the In-Part database.'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Connect to db and create a cursor for subsequent queries. \"\"\"\n",
    "        self.con = mdb.connect(host='localhost', user='root', passwd=\"123\", db=\"capstone\", local_infile=1) \n",
    "        self.cur = self.con.cursor() \n",
    "        \n",
    "        # Other auxiliary instance variables\n",
    "        self.user_num = None\n",
    "        self.user_ids = None\n",
    "        self.user_keywords = None\n",
    "        \n",
    "        self.tech_num = None\n",
    "        self.tech_ids = None\n",
    "        self.tech_keywords = None\n",
    "        \n",
    "        self.all_keywords = None\n",
    "        self.keyword_mapping_dict = None\n",
    "        \n",
    "        self.tech_mapping_dict = None\n",
    "\n",
    "    def get_user_num(self):\n",
    "        \"\"\"Return the number of unique users.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        long\n",
    "        \"\"\"\n",
    "        if self.user_num is not None:\n",
    "            return self.user_num\n",
    "        query = \"SELECT DISTINCT id FROM users\"\n",
    "        self.cur.execute(query)\n",
    "        self.user_num =  self.cur.rowcount\n",
    "        return long(self.user_num)\n",
    "\n",
    "    def get_user_ids(self):\n",
    "        \"\"\"Return a list of all user ids in the database. \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of long like [1L, 2L, 3L].\n",
    "        \"\"\"\n",
    "        if self.user_ids is not None:\n",
    "            return self.user_ids\n",
    "        query = \"SELECT DISTINCT id FROM users\"\n",
    "        self.cur.execute(query)\n",
    "        rows = self.cur.fetchall()\n",
    "        self.user_ids = [row[0] for row in rows]\n",
    "        return self.user_ids\n",
    "\n",
    "\n",
    "    def get_tech_num(self):\n",
    "        \"\"\"Return the number of unique technologies in the database.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        long        \n",
    "        \"\"\"\n",
    "        if self.tech_num is not None:\n",
    "            return self.tech_num\n",
    "        query = \"SELECT DISTINCT id FROM technologies\"\n",
    "        self.cur.execute(query)\n",
    "        self.technology_num = self.cur.rowcount\n",
    "        return self.technology_num\n",
    "\n",
    "    def get_tech_ids(self):\n",
    "        \"\"\"Return a list of all technologies id in the database.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of long.\n",
    "        \"\"\"\n",
    "        if self.tech_ids is not None:\n",
    "            return self.tech_ids\n",
    "        query = \"SELECT DISTINCT id FROM technologies\"\n",
    "        self.cur.execute(query)\n",
    "        rows = self.cur.fetchall()\n",
    "        self.tech_ids = [row[0] for row in rows]\n",
    "        return self.tech_ids\n",
    "\n",
    "    def get_tech_mapping_dict(self):\n",
    "        '''Return a mapping dict which maps technology id to its index in the lis of all tech ids.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "        '''\n",
    "        if self.tech_mapping_dict is not None:\n",
    "            return self.tech_mapping_dict\n",
    "        all_tech_ids = self.get_tech_ids()\n",
    "        self.tech_mapping_dict = {value: index for index, value in enumerate(all_tech_ids)}\n",
    "        return self.tech_mapping_dict\n",
    "    \n",
    "    \n",
    "    def get_all_keywords(self):\n",
    "        \"\"\"Return a list of all keywords.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list \n",
    "            A list of long.\n",
    "        \"\"\"\n",
    "        if self.all_keywords is not None:\n",
    "            return self.all_keywords\n",
    "        query = \"SELECT DISTINCT id FROM keywords\"\n",
    "        self.cur.execute(query)\n",
    "        rows = self.cur.fetchall()\n",
    "        self.all_keywords = [row[0] for row in rows]\n",
    "        return self.all_keywords\n",
    "        \n",
    "    def get_tech_keywords(self):\n",
    "        \"\"\"Return a dictionary whose key is technology id and whose value is a list of associated keywords.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict \n",
    "        \"\"\"\n",
    "        if self.tech_keywords is not None:\n",
    "            return self.tech_keywords\n",
    "        query = \"SELECT * FROM technology_keywords\"\n",
    "        self.cur.execute(query)\n",
    "        self.tech_keywords = {}\n",
    "        rows = self.cur.fetchall()\n",
    "        for row in rows:\n",
    "            if row[1] not in self.tech_keywords:\n",
    "                self.tech_keywords[row[1]] = []\n",
    "                self.tech_keywords[row[1]].append(row[0])\n",
    "            else:\n",
    "                self.tech_keywords[row[1]].append(row[0])\n",
    "        return self.tech_keywords\n",
    "    \n",
    "    def get_user_keywords(self):\n",
    "        \"\"\"Return a dictionary whose key is user id and whose value is a list of associated keywords.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict \n",
    "        \"\"\"\n",
    "        if self.user_keywords is not None:\n",
    "            return self.user_keywords\n",
    "        query = \"SELECT * FROM user_keywords\"\n",
    "        self.cur.execute(query)\n",
    "        self.user_keywords = {}\n",
    "        rows = self.cur.fetchall()\n",
    "        for row in rows:\n",
    "            if row[1] not in self.user_keywords:\n",
    "                self.user_keywords[row[1]] = []\n",
    "                self.user_keywords[row[1]].append(row[0])\n",
    "            else:\n",
    "                self.user_keywords[row[1]].append(row[0])\n",
    "        return self.user_keywords\n",
    "        \n",
    "        \n",
    "    def get_keyword_mapping_dict(self):\n",
    "        '''Return a mapping dict which maps keyword id to its index in the technology/user keyword vector.\n",
    "        \n",
    "        Note\n",
    "        ----\n",
    "        A technology id has many associated keywords. \n",
    "        A technology keyword vector of a technology id is a vector where the value of at that location of a keyword is 1 \n",
    "        if this technology id has that keyword.\n",
    "        \n",
    "        A user keyword vector has the same principle.\n",
    "        '''\n",
    "        if self.keyword_mapping_dict is not None:\n",
    "            return self.keyword_mapping_dict\n",
    "        all_keywords = self.get_all_keywords()\n",
    "        self.keyword_mapping_dict = {value: index for index, value in enumerate(all_keywords)}\n",
    "        return self.keyword_mapping_dict\n",
    "    \n",
    "    \n",
    "    def get_tech_keyword_vector(self, tech_id):\n",
    "        '''Return the technology keyword vector given a technology id.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        tech_id: long\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of int.\n",
    "        '''\n",
    "        tech_keyword_vector = np.zeros(len(self.get_all_keywords()), dtype=np.int8)\n",
    "        tech_keywords = self.get_tech_keywords().get(tech_id, None)\n",
    "        if tech_keywords is None:       # No keywords associated with this technology\n",
    "            return tech_keyword_vector\n",
    "        keyword_mapping_dict = self.get_keyword_mapping_dict()\n",
    "        indices = [keyword_mapping_dict[keyword] for keyword in tech_keywords]\n",
    "        tech_keyword_vector[indices] = 1\n",
    "        return tech_keyword_vector\n",
    "    \n",
    "    def get_user_keyword_vector(self, user_id):\n",
    "        '''Return the user keyword vector given a user id.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        user_id: str\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of int.\n",
    "        '''\n",
    "        user_keyword_vector = np.zeros(len(self.get_all_keywords()), dtype=np.int8)\n",
    "        user_keywords = self.get_user_keywords().get(user_id, None)\n",
    "        if user_keywords is None:       # No keywords associated with this user\n",
    "            return user_keyword_vector\n",
    "        keyword_mapping_dict = self.get_keyword_mapping_dict()\n",
    "        indices = [keyword_mapping_dict[keyword] for keyword in user_keywords]\n",
    "        user_keyword_vector[indices] = 1\n",
    "        return user_keyword_vector    \n",
    "    \n",
    "    def get_score_data(self):\n",
    "        \"\"\"Returns the score table.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "            A table which contains columns user_id, technology_id, total_score.\n",
    "        \"\"\"\n",
    "        self.scoreData = pd.read_sql(\"SELECT user_id, technology_id, total_score FROM score\", con = self.con)        \n",
    "        return self.scoreData\n",
    "    \n",
    "    def get_interacted_tech_ids(self, user_id):\n",
    "        \"\"\"Return a list of technology ids with which this user has interacted.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        user_id: str\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "        \"\"\"         \n",
    "        query = \"SELECT technology_id FROM score WHERE user_id = '%s'\" % user_id\n",
    "        self.cur.execute(query)              \n",
    "        rows = self.cur.fetchall()\n",
    "        return [row[0] for row in rows]\n",
    "     \n",
    "    def get_contacted_tech_ids (self, user_id):\n",
    "        \"\"\"Return a list of contacted technology ids given a user id.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of long.\n",
    "        \"\"\"\n",
    "        query =\"SELECT technology_id FROM contacts WHERE user_id = '%s'\" % user_id\n",
    "        self.cur.execute(query) \n",
    "        rows = self.cur.fetchall() \n",
    "        return [row[0] for row in rows]\n",
    "    \n",
    "    \n",
    "    def get_clicked_tech_ids (self, user_id):\n",
    "        \"\"\"Return a list of clicked technology ids in all emails containing recommended tech ids given a user id.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of long.\n",
    "        \"\"\"\n",
    "        query =\"SELECT clicked_technology_id FROM email_clicks WHERE user_id = '%s'\" % user_id\n",
    "        self.cur.execute(query) \n",
    "        rows = self.cur.fetchall() \n",
    "        return [row[0] for row in rows]\n",
    "    \n",
    "    def get_university_tech_ids(self, university_id):\n",
    "        \"\"\"Return a list of technology ids associated with this given university id.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of long.\n",
    "        \"\"\"\n",
    "        query = \"SELECT id FROM technologies WHERE university_profile_id = '%s'\" % university_id   \n",
    "        self.cur.execute(query)\n",
    "        rows = self.cur.fetchall()\n",
    "        return [row[0] for row in rows]   \n",
    "    \n",
    "    def get_orphan_tech_ids(self):\n",
    "        \"\"\"Find orphan tech ids in user_activtivies table.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            tech_ids which appear in the user_activities table, but not in the technologies table\n",
    "        \"\"\"   \n",
    "        activities = self.get_activities_table()\n",
    "        viewed_tech_ids = []\n",
    "        for index, row in activities.iterrows():\n",
    "            start = row[1].find(\"Article_id\") # Finding start from \"Article_id\"\n",
    "            end = row[1].find(\"content\")\n",
    "            tech_id = int(re.search(r'\\d+', row[1][start:end]).group(0))\n",
    "            viewed_tech_ids.append(tech_id)     \n",
    "        tech_ids = self.get_tech_ids() \n",
    "        orphan_tech_ids = list(set(tech_ids) - set(viewed_tech_ids))\n",
    "        return orphan_tech_ids\n",
    "\n",
    "    def get_contacts_table(self):\n",
    "        \"\"\"Return the contact table.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame \n",
    "            A table which contains columns user_id, technology_id, number of contacts.\n",
    "        \"\"\"\n",
    "        self.contacts = pd.read_sql( \"SELECT user_id, technology_id , count(*) as c_count FROM contacts group by user_id, technology_id\", con = self.con)    \n",
    "        return self.contacts\n",
    "    \n",
    "    def get_clicks_table(self):\n",
    "        \"\"\"Return the click table.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame   \n",
    "            A table which contains columns user_id, technology_id, number of clicks.\n",
    "        \"\"\"\n",
    "        self.clicks =  pd.read_sql( \"SELECT user_id, clicked_technology_id as technology_id, count(*) as e_count FROM email_clicks group by user_id, technology_id\", con = self.con)\n",
    "        return self.clicks\n",
    "\n",
    "    def get_activities_table(self):\n",
    "        \"\"\"Return the activities table.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame   \n",
    "            A table which contains columns user_id, details.\n",
    "        \"\"\"\n",
    "        self.activities = pd.read_sql( \"SELECT user_id, details FROM user_activities\", con = self.con) \n",
    "        return self.activities   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = DataReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1261L"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_user_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['525fea18-db1c-451d-9902-469ad4718e13',\n",
       " '525ff28d-2d28-4cf2-a4d8-468bd4718e13',\n",
       " '5260234c-9878-4d49-9d26-46b2d4718e13',\n",
       " '5260f967-7d74-4f6e-9deb-4b7fd4718e13',\n",
       " '526131a8-dbc8-401b-989a-44afd4718e13']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_user_ids()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dr.get_user_keywords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dr.get_user_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dr.get_user_keywords().get('526132a9-4280-4cc4-a2d8-42acd4718e13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_user_keyword_vector('526132a9-4280-4cc4-a2d8-42acd4718e13').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338L, [2L, 3L, 4L, 5L, 6L])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_tech_num(), dr.get_tech_ids()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 848)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dr.get_tech_mapping_dict()), max([item[1] for item in dr.get_tech_mapping_dict().items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dr.get_tech_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_tech_keyword_vector(2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1L, 2L, 3L, 4L, 5L]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_all_keywords()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7429"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( dr.get_all_keywords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35L]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_clicked_tech_ids('57d97d4a-23b8-4148-a0a5-004a0a2ae3a6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60L, 40L, 23L, 64L, 41L, 47L, 51L]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_contacted_tech_ids('532a4687-92a4-4b5b-9d92-4f05d4718e13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dr.get_orphan_tech_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dr.get_orphan_tech_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dr.get_tech_ids()) & set(dr.get_orphan_tech_ids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dr.get_tech_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804,)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_score_data()['user_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(738,)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_score_data()['technology_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cosine_similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import DataReader as dr\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from scipy import sparse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_set = 0\n",
    "item_set = 0\n",
    "null_set = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statr building tech keyword sim matrix...\n",
      "Dim of item: (1338, 1338)\n",
      "Done.\n",
      "\n",
      "\n",
      "Statr building item_based Collaborative Filtering sim matrix...\n",
      "item set set([2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 298, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 390, 391, 394, 395, 396, 397, 398, 400, 401, 402, 403, 410, 412, 413, 414, 415, 416, 417, 419, 421, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 557, 559, 560, 561, 562, 563, 564, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 662, 663, 664, 665, 666, 667, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 700, 701, 702, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 744, 747, 748, 749, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 793, 796, 798, 799, 801, 802, 803, 805, 806, 807, 808, 809, 810, 811, 812, 813, 815, 816, 818, 819, 820, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 835, 836, 838, 839, 840, 841, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 856, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 917, 918, 919, 920, 921, 922, 923, 924, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 943, 944, 945, 946, 949, 950, 953, 960, 961, 962, 963, 964, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 989, 990, 991, 992, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1012, 1013, 1014, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1031, 1032, 1033, 1034, 1035, 1039, 1040, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1067, 1068, 1070, 1071, 1072, 1073, 1074, 1075, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1087, 1089, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1103, 1104, 1105, 1106, 1108, 1110, 1111, 1112, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1125, 1127, 1128, 1130, 1131, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1142, 1145, 1146, 1147, 1148, 1150, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1174, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1187, 1189, 1190, 1194, 1195, 1196, 1197, 1198, 1199, 1201, 1205, 1208, 1209, 1210, 1211, 1212, 1214, 1215, 1216, 1217, 1218, 1220, 1221, 1223, 1225, 1227, 1229, 1231, 1232, 1233, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1246, 1247, 1248, 1249, 1250, 1252, 1254, 1255, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1267, 1268, 1269, 1270, 1271, 1272, 1274, 1277, 1278, 1279, 1281, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1295, 1296, 1297, 1298, 1299, 1300, 1304, 1308, 1310, 1311, 1317, 1323, 1325, 1326, 1328, 1329, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1350, 1351, 1356, 1357, 1359, 1364, 1370, 1371, 1372, 1373, 1374])\n",
      "Dim of item: (1164, 1164)\n",
      "Done.\n",
      "\n",
      "\n",
      "Statr building Ensemble sim matrix...\n",
      "178\n",
      "1338\n",
      "1164\n",
      "Done.\n",
      "\n",
      "\n",
      "Start writing recommendations to the database...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class EnsembleRecommenderForTechnology(object):\n",
    "    '''An ensemble recommender to recommend technologies for a tehchnology.\n",
    "    \n",
    "    Frist, calculate technology similarities between technology keyword vector.\n",
    "    Second, calculate technology similarities between columns of utility matrix. Each technology vector is represented by scores given by users.\n",
    "    Finally, do a weighted average of two technology matrix. The weights are [0.5, 0.5].\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.dr = DataReader()\n",
    "        \n",
    "        self.score = self.dr.get_score_data()\n",
    "        self.tech_keyword_matrix = self.get_tech_keyword_matrix() \n",
    "        \n",
    "        self.tech_keyword_sim_matrix = None\n",
    "        self.item_based_sim_matrix = None\n",
    "        self.ensemble_sim_matrix = None\n",
    "        \n",
    "        # Auxiliary variable\n",
    "        self.tech_id_set_for_item_based = None\n",
    "    \n",
    "    def build_tech_keyword_sim_matrix(self):\n",
    "        if self.tech_keyword_sim_matrix is not None:\n",
    "            return self.tech_keyword_sim_matrix\n",
    "        \n",
    "        print \"Statr building tech keyword sim matrix...\"\n",
    "        self.tech_keyword_matrix = sparse.csr_matrix(self.tech_keyword_matrix)\n",
    "        self.tech_keyword_sim_matrix = pd.DataFrame(cosine_similarity(self.tech_keyword_matrix),\n",
    "                                                    index=self.dr.get_tech_ids(),\n",
    "                                                    columns=self.dr.get_tech_ids())\n",
    "        print \"Done.\"\n",
    "        print '\\n'\n",
    "        \n",
    "    def build_item_based_cl_sim_matrix(self):\n",
    "        if self.item_based_sim_matrix is not None:\n",
    "            return self.item_based_sim_matrix\n",
    "        \n",
    "        print \"Statr building item_based Collaborative Filtering sim matrix...\"\n",
    "        scoreData = self.score\n",
    "        score_df = scoreData.pivot(index = 'user_id', columns = 'technology_id', values = 'total_score') # Reshape score table \n",
    "        score_df = score_df.fillna(0) # fill NaN data with 0\n",
    "\n",
    "        # Calculate Technology based similarity\n",
    "        score_df_t = score_df.T\n",
    "        score_spare_t = sparse.csr_matrix(score_df_t) \n",
    "\n",
    "        similarities_tech = cosine_similarity(score_spare_t)\n",
    "        similarities_tech_df = pd.DataFrame(similarities_tech, columns=score_df_t.index, index=score_df_t.index)\n",
    "        self.item_based_sim_matrix = similarities_tech_df\n",
    "        self.tech_id_set_for_item_based = set(self.item_based_sim_matrix.index)\n",
    "\n",
    "        print \"Done.\"\n",
    "        print '\\n'    \n",
    "\n",
    "    def build_ensemble_model(self):\n",
    "        if self.ensemble_sim_matrix is not None:\n",
    "            return self.ensemble_sim_matrix\n",
    "        \n",
    "        print \"Statr building Ensemble sim matrix...\"\n",
    "        ensemble_sim_matrix = (self.tech_keyword_sim_matrix + self.item_based_sim_matrix) / 2\n",
    "        ensemble_sim_matrix = ensemble_sim_matrix.loc[self.dr.get_tech_ids(), self.dr.get_tech_ids()]        \n",
    "\n",
    "        # Replace null values of Item based sim matrix with similarity values in Technology keyword sim matrix\n",
    "        all_tech_ids = set(self.dr.get_tech_ids())\n",
    "        tech_ids_null_set = all_tech_ids - self.tech_id_set_for_item_based        \n",
    "        for tech_id in tech_ids_null_set:\n",
    "            ensemble_sim_matrix.loc[tech_id] = self.tech_keyword_sim_matrix.loc[tech_id]\n",
    "            ensemble_sim_matrix.loc[:, tech_id] = self.tech_keyword_sim_matrix.loc[:, tech_id]\n",
    "        \n",
    "        self.ensemble_sim_matrix = ensemble_sim_matrix\n",
    "        print \"Done.\"\n",
    "        print '\\n'  \n",
    "        \n",
    "    def ensemble_recommend(self, tid, k):\n",
    "        '''Return top k recommendations for a user id.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        tid: int\n",
    "            technology id\n",
    "        k: int\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "        '''\n",
    "        tech_sim = zip(self.ensemble_sim_matrix.loc[tid], self.dr.get_tech_ids())\n",
    "        tech_sim = sorted(tech_sim, key=lambda x: x[0], reverse=True)[1:k+1]\n",
    "        return [tech_id for sim, tech_id in tech_sim]\n",
    "    \n",
    "    def save_recommendations_to_database(self, k):\n",
    "        '''Create a table and Write top k recommendations for technology to the database.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        k: int\n",
    "            The number of recommendations for each technology.\n",
    "        '''\n",
    "        print \"Start writing recommendations to the database...\"\n",
    "        tech_ids = self.dr.get_tech_ids()\n",
    "        recommendations = pd.DataFrame([self.ensemble_recommend(tid, k) for tid in tech_ids], \n",
    "                                       index=tech_ids)\n",
    "        \n",
    "        recommendations.to_csv('ensemble_recommendations_for_techs.txt', sep='\\t', header=False)\n",
    "        \n",
    "        top_k_str = \"\"\n",
    "        for i in range(1, k + 1):\n",
    "            top_k_str += \"top_\" + str(i) + \" int, \"\n",
    "        self.dr.cur.execute(\"DROP TABLE IF EXISTS RecommendationResultForTechs;\")\n",
    "        self.dr.cur.execute('''CREATE TABLE RecommendationResultForTechs (\n",
    "                                   technology_id int,\n",
    "                                   %s);''' % top_k_str[:-2])\n",
    "        self.dr.cur.execute('''LOAD DATA LOCAL INFILE 'ensemble_recommendations_for_techs.txt' \n",
    "                                   INTO TABLE RecommendationResultForTechs \n",
    "                                   FIELDS TERMINATED BY '\\t' \n",
    "                                   LINES TERMINATED BY '\\n';''')\n",
    "        self.dr.con.commit()\n",
    "        print \"Done\"\n",
    "    \n",
    "    def get_tech_keyword_matrix(self):\n",
    "        '''Return a technology keyword matrix whose row is a technology keyword vector.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        A list of list\n",
    "        '''\n",
    "        all_tech_ids = self.dr.get_tech_ids()\n",
    "        tech_keyword_matrix = []     # Dimension: num_techs * num_keywords\n",
    "        for tech_id in all_tech_ids:\n",
    "            tech_keyword_matrix.append(self.dr.get_tech_keyword_vector(tech_id))\n",
    "        return tech_keyword_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    recommender = EnsembleRecommenderForTechnology()\n",
    "    recommender.build_tech_keyword_sim_matrix()\n",
    "    recommender.build_item_based_cl_sim_matrix()\n",
    "    recommender.build_ensemble_model()\n",
    "    recommender.save_recommendations_to_database(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1342"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1164 + 178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(null_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recommender.dr.get_tech_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training content_based model...\n",
      "Done\n",
      "Time elapsed: 0:00:00.156338 \n",
      "\n",
      "Start training interacted content_based model...\n",
      "Done\n",
      "Time elapsed: 0:00:20.021226 \n",
      "\n",
      "Start training collaborative filtering model...\n",
      "Total num of calculation: 593352\n",
      "Num of calcuation finished: 100000 \tTime elapsed: 0:01:14.511157\n",
      "Num of calcuation finished: 200000 \tTime elapsed: 0:02:27.499231\n",
      "Num of calcuation finished: 300000 \tTime elapsed: 0:03:36.634235\n",
      "Num of calcuation finished: 400000 \tTime elapsed: 0:04:50.123190\n",
      "Num of calcuation finished: 500000 \tTime elapsed: 0:06:05.845653\n",
      "Done\n",
      "Time elapsed: 0:07:08.014944 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Chaofan/anaconda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:181: Warning: Unknown table 'capstone.recommendationresultforusers'\n"
     ]
    }
   ],
   "source": [
    "class EnsembleRecommender(object):\n",
    "    '''An ensemble recommender integrated from two content-based models and one item-based collaborative flitering.'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dr = DataReader()\n",
    "        \n",
    "        self.score = self.dr.get_score_data()\n",
    "        self.cb_matrix = None\n",
    "        self.interacted_cb_matrix = None\n",
    "        self.cl_matrix = None\n",
    "        self.ensemble_matrix = None\n",
    "        self.tech_keyword_matrix = self.get_tech_keyword_matrix()\n",
    "        \n",
    "    def build_content_based(self):\n",
    "        '''Build a content-based model which calculates similarity between user keyword vector and tech keyword vector.'''\n",
    "        if self.cb_matrix is not None:\n",
    "            return self.cb_matrix\n",
    "        \n",
    "        print 'Start training content_based model...'\n",
    "        start = datetime.now()\n",
    "        \n",
    "        all_user_ids = self.dr.get_user_ids()\n",
    "        user_keyword_matrix = []     # Dimension: num_users * num_keywords\n",
    "        for uid in all_user_ids:\n",
    "            user_keyword_matrix.append(self.dr.get_user_keyword_vector(uid))\n",
    "        \n",
    "        # Convert matrix to sparse matrix to speed up similarity calculation\n",
    "        user_keyword_matrix = sparse.csr_matrix(user_keyword_matrix)\n",
    "        self.tech_keyword_matrix = sparse.csr_matrix(self.tech_keyword_matrix)\n",
    "        self.cb_matrix = cosine_similarity(user_keyword_matrix, self.tech_keyword_matrix)  # Dim: num_users * num_techs\n",
    "        print 'Done'\n",
    "        print 'Time elapsed:', datetime.now() - start, '\\n'\n",
    "        \n",
    "    def build_interacted_content_based(self):\n",
    "        '''Build a intereacted cb model which calculates similarity between user preference vector and tech keyword vector.\n",
    "        \n",
    "        The user preference vector is a weighted average of tech keyword vectors with which users have interacted.\n",
    "        '''\n",
    "        if self.interacted_cb_matrix is not None:\n",
    "            return self.interacted_cb_matrix\n",
    "        \n",
    "        self.tech_keyword_matrix = self.tech_keyword_matrix.toarray()\n",
    "        \n",
    "        print 'Start training interacted content_based model...'\n",
    "        start = datetime.now()\n",
    "        all_user_ids = self.dr.get_user_ids()\n",
    "        tech_mapping_dict = self.dr.get_tech_mapping_dict()\n",
    "        user_keyword_matrix = []\n",
    "        for uid in all_user_ids:\n",
    "            interacted_tech_ids = self.dr.get_interacted_tech_ids(uid)\n",
    "            num = np.zeros(len(self.dr.get_all_keywords()), dtype=np.float32)\n",
    "            deno = 0\n",
    "            for tech_id in interacted_tech_ids:\n",
    "                d= self.score[(self.score['user_id'] == uid) & (self.score['technology_id'] == tech_id)]['total_score']\n",
    "    \n",
    "                weight = d.values[0]\n",
    "                num += weight * self.tech_keyword_matrix[tech_mapping_dict[tech_id], :]\n",
    "                deno += weight\n",
    "            if deno == 0:    # This user hasn't interacted with any technology\n",
    "                user_keyword_matrix.append(self.dr.get_user_keyword_vector(uid))\n",
    "            else:\n",
    "                user_keyword_matrix.append(num / deno)\n",
    "\n",
    "        # Convert matrix to sparse matrix to speed up similarity calculation\n",
    "        user_keyword_matrix = sparse.csr_matrix(user_keyword_matrix)\n",
    "        self.tech_keyword_matrix = sparse.csr_matrix(self.tech_keyword_matrix)\n",
    "        self.interacted_cb_matrix = cosine_similarity(user_keyword_matrix, self.tech_keyword_matrix)  # Dim: num_users * num_techs\n",
    "        print 'Done'\n",
    "        print 'Time elapsed:', datetime.now() - start, '\\n'\n",
    "            \n",
    "    def build_collaborative_filtering(self):\n",
    "        '''Built a collaborative filtering model using score table.'''\n",
    "        if self.cl_matrix is not None:\n",
    "            return self.cl_matrix\n",
    "        \n",
    "        scoreData = self.score\n",
    "        score_df = scoreData.pivot(index = 'user_id', columns = 'technology_id', values = 'total_score') # Reshape score table \n",
    "        score_df = score_df.fillna(0) # fill NaN data with 0\n",
    "\n",
    "        # Calculate Technology based similarity\n",
    "        score_df_t = score_df.T\n",
    "        score_spare_t = sparse.csr_matrix(score_df_t) \n",
    "\n",
    "        similarities_tech = cosine_similarity(score_spare_t)\n",
    "        similarities_tech_df = pd.DataFrame(similarities_tech, columns = score_df_t.index, index = score_df_t.index)\n",
    "\n",
    "        # Create a list of user_ids and tech_ids which are available in score table\n",
    "        user_ids = scoreData['user_id'].unique()\n",
    "        tech_ids = scoreData['technology_id'].unique()\n",
    "\n",
    "        # Calculate mean of all ratings, mean rating given by each user and mean rating given to each technology\n",
    "        all_mean = np.mean(scoreData['total_score'])\n",
    "        avg_user = {}\n",
    "        for user in user_ids:\n",
    "            avg_user[user] = np.mean(scoreData[scoreData['user_id'] == user]['total_score']) - all_mean\n",
    "\n",
    "        avg_tech = {}\n",
    "        for tech in tech_ids:\n",
    "            avg_tech[tech] = np.mean(scoreData[scoreData['technology_id'] == tech]['total_score'])-all_mean\n",
    "        \n",
    "        \n",
    "        print 'Start training collaborative filtering model...'\n",
    "        start = datetime.now()\n",
    "        count = 0\n",
    "        base_line = {}\n",
    "        prediction = {} # A dictionary storing predictions whose key is a tuple (user_id, tech_id)\n",
    "        \n",
    "        print 'Total num of calculation:', len(user_ids) * len(tech_ids)\n",
    "        for i in itertools.product(user_ids,tech_ids):\n",
    "            prediction[i] = score_df.ix[i[0],i[1]]\n",
    "            base_line[i] = avg_user[i[0]] + avg_tech[i[1]] + all_mean\n",
    "            if prediction[i] == 0:\n",
    "                numerator = sum((score_df.ix[i[0]] - base_line[i])*similarities_tech_df.ix[i[1]])\n",
    "                denominator = sum(similarities_tech_df.ix[i[1]])-1\n",
    "                if denominator == 0:\n",
    "                    prediction[i] = 0\n",
    "                else:\n",
    "                    prediction[i] = base_line[i] + numerator/float(denominator)\n",
    "                    count += 1\n",
    "                    if count % 100000 == 0:\n",
    "                        print 'Num of calcuation finished:', count,\n",
    "                        print '\\tTime elapsed:', datetime.now() - start\n",
    "\n",
    "        idx = pd.MultiIndex.from_tuples(prediction.keys())\n",
    "        item_based_cf = pd.DataFrame(list(prediction.values()),index = idx,columns = ['Technology_id']).unstack(fill_value = 0)['Technology_id']\n",
    "        item_based_cf = item_based_cf.loc[self.dr.get_user_ids(), self.dr.get_tech_ids()].fillna(0)\n",
    "        self.cl_matrix = item_based_cf.values\n",
    "        print 'Done'\n",
    "        print 'Time elapsed:', datetime.now() - start, '\\n'\n",
    "        \n",
    "    \n",
    "    def build_ensemble_model(self, weights):\n",
    "        '''Build an ensemble model.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        weights: list\n",
    "            Ensemble weights of item_based cf, content_based, interacted_content_based.\n",
    "        '''\n",
    "        if self.ensemble_matrix is not None:\n",
    "            return self.ensemble_matrix\n",
    "        index = self.dr.get_user_ids()\n",
    "        cols = self.dr.get_tech_ids()\n",
    "        norm_item_based_cf = self.normalize_df(pd.DataFrame(self.cl_matrix, index=index, columns=cols))\n",
    "        norm_cb = self.normalize_df(pd.DataFrame(self.cb_matrix, index=index, columns=cols))\n",
    "        norm_interacted_cb = self.normalize_df(pd.DataFrame(self.interacted_cb_matrix, index=index, columns=cols))\n",
    "        \n",
    "        weighted_ensemble = norm_item_based_cf * weights[0] + norm_cb * weights[1] + norm_interacted_cb * weights[2]\n",
    "        self.ensemble_matrix = weighted_ensemble\n",
    "    \n",
    "    def ensemble_recommend(self, uid, k):\n",
    "        '''Return top k recommendations for a user id.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple (a list of top k recommendations, a list of tech ids clicked in emails)\n",
    "        '''\n",
    "        user_preds = zip(self.ensemble_matrix.loc[uid], self.dr.get_tech_ids())\n",
    "        user_preds = sorted(user_preds, key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        contacted_ids = self.dr.get_contacted_tech_ids(uid)\n",
    "        top_k = [item_id for score, item_id in user_preds if item_id not in contacted_ids][:k]\n",
    "        \n",
    "        clicked_tech_ids = self.dr.get_clicked_tech_ids(uid)\n",
    "        email_clicked = [tech_id for tech_id in top_k if long(tech_id) in clicked_tech_ids]\n",
    "        return top_k, email_clicked\n",
    "\n",
    "    def save_recommendations_to_database(self, k):\n",
    "        '''Create a table and Write top k recommendations for each user to the database.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        k: int\n",
    "            The number of recommendations for each user.\n",
    "        '''\n",
    "        uids = self.dr.get_user_ids()\n",
    "        result = [self.ensemble_recommend(uid, k) for uid in uids]\n",
    "        recommendations = [item[0] for item in result]\n",
    "        email_clicked = [item[1] for item in result]\n",
    "        output = pd.concat([pd.DataFrame({'user_id': uids}), pd.DataFrame(recommendations), pd.DataFrame({'email_clicked': email_clicked})], axis=1)\n",
    "        output.to_csv('ensemble_recommendations_for_users.txt', sep='\\t', index=False, header=False)\n",
    "        \n",
    "        top_k_str = \"\"\n",
    "        for i in range(1, k + 1):\n",
    "            top_k_str += \"top_\" + str(i) + \" int, \"\n",
    "        self.dr.cur.execute(\"DROP TABLE IF EXISTS RecommendationResultForUsers;\")\n",
    "        self.dr.cur.execute('''CREATE TABLE RecommendationResultForUsers (\n",
    "                                   user_id VARCHAR(60),\n",
    "                                   %s \n",
    "                                   email_clicked VARCHAR(220));''' % top_k_str)\n",
    "        self.dr.cur.execute('''LOAD DATA LOCAL INFILE 'ensemble_recommendations_for_users.txt' \n",
    "                                   INTO TABLE RecommendationResultForUsers \n",
    "                                   FIELDS TERMINATED BY '\\t' \n",
    "                                   LINES TERMINATED BY '\\n';''')\n",
    "        self.dr.con.commit()\n",
    "\n",
    "    \n",
    "    def get_tech_keyword_matrix(self):\n",
    "        '''Return a technology keyword matrix whose row is a technology keyword vector.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        A list of list\n",
    "        '''\n",
    "        all_tech_ids = self.dr.get_tech_ids()\n",
    "        tech_keyword_matrix = []     # Dimension: num_techs * num_keywords\n",
    "        for tech_id in all_tech_ids:\n",
    "            tech_keyword_matrix.append(self.dr.get_tech_keyword_vector(tech_id))\n",
    "        return tech_keyword_matrix\n",
    "    \n",
    "    def normalize_df(self, score_matrix):\n",
    "        '''Normalize the range of each user's score to [0,1].\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        score_matrix: DataFrame\n",
    "            Row is user, Column is technology, Value is the score. Recommendations are made by ranking scores for a user.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame\n",
    "        '''\n",
    "        norm_df = score_matrix.copy()\n",
    "        for idx, row in norm_df.iterrows():\n",
    "            min_val = min(row)\n",
    "            max_val = max(row)\n",
    "            interval = max_val - min_val\n",
    "            if interval == 0:\n",
    "                continue\n",
    "            norm_df.ix[idx] = [(r - min_val) / interval for r in row]\n",
    "        return norm_df\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    ensemble_weights = [0.65, 0.67, 0.52]\n",
    "    recommender = EnsembleRecommender()\n",
    "    recommender.build_content_based()\n",
    "    recommender.build_interacted_content_based()\n",
    "    recommender.build_collaborative_filtering()\n",
    "    recommender.build_ensemble_model(ensemble_weights)\n",
    "    recommender.save_recommendations_to_database(10)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DataReaderplus import *\n",
    "cols = weighted_ensemble.columns\n",
    "dr = DataReader()\n",
    "\n",
    "def ensemble_recommend(uid, k):\n",
    "    ''' Returns top k recommendations for a user id '''\n",
    "    user_preds = zip(weighted_ensemble.loc[uid], cols)\n",
    "    user_preds = sorted(user_preds, key=lambda x: x[0], reverse=True)\n",
    "    contact_ids = dr.get_contacted_tech_ids(uid)\n",
    "    top_k = [item_id for score, item_id in user_preds if item_id not in contact_ids][:k]\n",
    "    return top_k\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    time = datetime.now()\n",
    "    uids = user_pool\n",
    "    recommendations = [ensemble_recommend(uid, 5) for uid in uids]\n",
    "    df = pd.DataFrame(recommendations)\n",
    "    email_clicked = []\n",
    "    for i, uid in enumerate(uids):\n",
    "        email_clicked.append([int(tech_id)  for tech_id in recommendations[i] if long(tech_id) in dr.get_clicked_tech_ids(uid)])\n",
    "    output = pd.concat([pd.DataFrame({'user_id': uids}), df, pd.DataFrame({'email_clicked': email_clicked})], axis=1)\n",
    "    output.to_csv('ensemble_recommendations.csv', index=False)\n",
    "    print 'Time elapsed: ', datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = EnsembleRecommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training content_based model...\n",
      "Done\n",
      "Time elapsed: 0:00:00.191848 \n",
      "\n",
      "Start training interacted content_based model...\n",
      "Done\n",
      "Time elapsed: 0:00:15.971555 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.build_content_based()\n",
    "e.build_interacted_content_based()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training collaborative filtering model...\n",
      "Total num of calculation: 593352\n",
      "Num of calcuation finished: 100000 \tTime elapsed: 0:01:21.140684\n",
      "Num of calcuation finished: 200000 \tTime elapsed: 0:02:37.001720\n",
      "Num of calcuation finished: 300000 \tTime elapsed: 0:03:56.585435\n",
      "Num of calcuation finished: 400000 \tTime elapsed: 0:05:12.438050\n",
      "Num of calcuation finished: 500000 \tTime elapsed: 0:06:33.723254\n",
      "Done\n",
      "Time elapsed: 0:07:45.710770 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.build_collaborative_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e.build_ensemble_model([0.65, 0.67, 0.52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(977, 849)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.ensemble_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('525fea18-db1c-451d-9902-469ad4718e13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'525fea18-db1c-451d-9902-469ad4718e13',\n",
       "       u'525ff28d-2d28-4cf2-a4d8-468bd4718e13',\n",
       "       u'5260234c-9878-4d49-9d26-46b2d4718e13',\n",
       "       u'5260f967-7d74-4f6e-9deb-4b7fd4718e13',\n",
       "       u'526131a8-dbc8-401b-989a-44afd4718e13',\n",
       "       u'526132a9-4280-4cc4-a2d8-42acd4718e13',\n",
       "       u'526640ab-ebd8-4593-9749-4002d4718e13',\n",
       "       u'52698ff9-0470-47c7-b027-d9c9d4718e13',\n",
       "       u'5283a1d7-dae0-4d34-b38f-493cd4718e13',\n",
       "       u'5283aeaa-d9e4-46ec-a318-3a1ed4718e13',\n",
       "       ...\n",
       "       u'5876357e-50a8-4584-bdbd-00860a2ac68a',\n",
       "       u'5877557e-bbac-4e3f-944a-00810a2a6136',\n",
       "       u'58775f13-5944-46d8-9ec7-00bd0a2a6136',\n",
       "       u'587788f1-a39c-473f-8294-008a0a2a6136',\n",
       "       u'5877e33e-21f8-472f-be30-00b70a2ac68a',\n",
       "       u'58788ee8-bd40-4c20-992f-008a0a2a6136',\n",
       "       u'5878982f-92f8-4803-8c4a-008a0a2a6136',\n",
       "       u'5878c1c5-fe60-4018-9a89-00810a2a6136',\n",
       "       u'5878f2d1-a1a8-4155-b583-00320a2a9d99',\n",
       "       u'5879fa50-eecc-4812-8892-002f0a2a2cca'],\n",
       "      dtype='object', length=977)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.ensemble_matrix.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([504L, 516L, 253L, 503L, 783L, 510L, 168L, 807L, 365L, 499L],\n",
       " [504L, 516L, 253L, 503L, 510L, 168L])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.ensemble_recommend('57ea95e3-5d44-4330-81df-00500a2abcf8', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(977, 849)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.cl_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-176-09420479894e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-176-09420479894e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    dr.get_score_data()[()'user_id'=='528f575a-c6a8-4fdb-9bd7-4662d4718e13') & 'technology_id' == 17L]['total_score']\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dr.get_score_data()[()'user_id'=='528f575a-c6a8-4fdb-9bd7-4662d4718e13') & 'technology_id' == 17L]['total_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = dr.get_score_data()\n",
    "s[(s['user_id']=='528f575a-c6a8-4fdb-9bd7-4662d4718e13') & (s['technology_id'] == 17L)]['total_score'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = EnsembleRecommender()\n",
    "e.build_content_based()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_tech_keyword_vector(3l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse.csr_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosine_similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(e.tech_keyword_matrix.toarray(), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.tech_keyword_matrix.toarray()[1, :].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(10, dtype=np.int8) + np.ones(10, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(10).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
